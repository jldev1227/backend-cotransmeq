import { Client } from 'pg';

// Base de datos ORIGEN
const sourceDb = new Client({
  host: '100.106.115.11',
  port: 5432,
  user: 'postgres',
  password: 'Transmeralda2025',
  database: 'transmeralda_db_18_7_2025', // Base de datos correcta con 394 servicios
  ssl: false
});

// Base de datos DESTINO (Azure)
const targetDb = new Client({
  host: 'cotransmeq.postgres.database.azure.com',
  port: 5432,
  user: 'admintransmeralda',
  password: 'SASesmeralda2025',
  database: 'postgres',
  ssl: {
    rejectUnauthorized: false
  }
});

// Mapeo de nombres de tablas (origen ‚Üí destino)
const tableMapping: Record<string, string> = {
  'user': 'usuarios',
  'empresa': 'clientes'
};

// Columnas a excluir por tabla (que existen en origen pero no en destino)
const columnsToExclude: Record<string, string[]> = {
  'conductores': ['old_id', 'licencia_conduccion'], // old_id no existe, licencia_conduccion es VARCHAR‚ÜíJSONB
  'documento': ['modelo_id']
};

// Orden correcto de migraci√≥n respetando foreign keys
const tablesToMigrate = [
  // 1. Tablas independientes primero
  { source: 'user', target: 'usuarios' },
  'municipios',
  'empresas', // Ya se llama igual en ambas bases
  
  // 2. Conductores y veh√≠culos (dependen de usuarios)
  'conductores',
  'vehiculos',
  
  // 3. Configuraciones
  'configuraciones_liquidacion',
  
  // 4. Liquidaciones (depende de conductores)
  'liquidaciones',
  
  // 5. Tablas que dependen de liquidaciones
  'liquidacion_vehiculo',
  'recargos',
  'anticipos',
  'bonificaciones',
  'pernotes',
  'mantenimientos',
  
  // 6. Servicios (depende de conductores, vehiculos, clientes, municipios)
  'servicios',
  'servicio_historicos',
  'liquidaciones_servicios',
  
  // 7. Documentos
  'documento'
];

interface MigrationResult {
  table: string;
  status: 'success' | 'error' | 'skipped';
  rowsCopied: number;
  error?: string;
  duration: number;
}

async function getTableColumns(client: Client, tableName: string): Promise<string[]> {
  const result = await client.query(`
    SELECT column_name 
    FROM information_schema.columns 
    WHERE table_schema = 'public' AND table_name = $1 
    ORDER BY ordinal_position
  `, [tableName]);
  
  return result.rows.map(row => row.column_name);
}

async function getTableColumnsWithTypes(client: Client, tableName: string): Promise<Map<string, string>> {
  const result = await client.query(`
    SELECT column_name, data_type 
    FROM information_schema.columns 
    WHERE table_schema = 'public' AND table_name = $1 
    ORDER BY ordinal_position
  `, [tableName]);
  
  const map = new Map<string, string>();
  result.rows.forEach(row => {
    map.set(row.column_name, row.data_type);
  });
  return map;
}

async function tableExists(client: Client, tableName: string): Promise<boolean> {
  const result = await client.query(`
    SELECT EXISTS (
      SELECT FROM information_schema.tables 
      WHERE table_schema = 'public' AND table_name = $1
    )
  `, [tableName]);
  
  return result.rows[0].exists;
}

async function migrateTable(sourceTable: string, targetTable: string): Promise<MigrationResult> {
  const startTime = Date.now();
  const result: MigrationResult = {
    table: targetTable,
    status: 'success',
    rowsCopied: 0,
    duration: 0
  };
  
  try {
    console.log(`\nüìã Migrando: ${sourceTable} ‚Üí ${targetTable}`);
    
    // Verificar que ambas tablas existan
    const sourceExists = await tableExists(sourceDb, sourceTable);
    const targetExists = await tableExists(targetDb, targetTable);
    
    if (!sourceExists) {
      console.log(`   ‚ö†Ô∏è  Tabla ${sourceTable} no existe en origen`);
      result.status = 'skipped';
      result.duration = Date.now() - startTime;
      return result;
    }
    
    if (!targetExists) {
      console.log(`   ‚ö†Ô∏è  Tabla ${targetTable} no existe en destino`);
      result.status = 'skipped';
      result.duration = Date.now() - startTime;
      return result;
    }
    
    // Obtener columnas de ambas tablas
    const sourceColumns = await getTableColumns(sourceDb, sourceTable);
    const targetColumns = await getTableColumns(targetDb, targetTable);
    const sourceColumnTypes = await getTableColumnsWithTypes(sourceDb, sourceTable);
    
    // Filtrar columnas: solo las que existen en ambas tablas
    const excludeList = columnsToExclude[targetTable] || [];
    const commonColumns = sourceColumns.filter(col => 
      targetColumns.includes(col) && !excludeList.includes(col)
    );
    
    if (commonColumns.length === 0) {
      console.log(`   ‚ö†Ô∏è  No hay columnas comunes entre las tablas`);
      result.status = 'skipped';
      result.duration = Date.now() - startTime;
      return result;
    }
    
    console.log(`   üìê Columnas a migrar: ${commonColumns.length}`);
    if (excludeList.length > 0) {
      console.log(`   üö´ Columnas excluidas: ${excludeList.join(', ')}`);
    }
    
    // Contar registros en origen
    const countResult = await sourceDb.query(`SELECT COUNT(*) as count FROM "${sourceTable}"`);
    const totalRows = parseInt(countResult.rows[0].count);
    
    if (totalRows === 0) {
      console.log(`   ‚ÑπÔ∏è  No hay datos en origen`);
      result.status = 'skipped';
      result.duration = Date.now() - startTime;
      return result;
    }
    
    console.log(`   üìä Registros en origen: ${totalRows}`);
    
    // Leer datos de origen
    const columnsList = commonColumns.map(c => `"${c}"`).join(', ');
    const sourceData = await sourceDb.query(`SELECT ${columnsList} FROM "${sourceTable}"`);
    
    // Limpiar tabla destino
    console.log(`   üóëÔ∏è  Limpiando tabla ${targetTable}...`);
    await targetDb.query(`TRUNCATE TABLE "${targetTable}" CASCADE`);
    
    // Insertar en lotes
    const batchSize = 100;
    let totalInserted = 0;
    
    // Para tablas con problemas JSON, insertar uno por uno
    const insertOneByOne = ['conductores', 'liquidaciones'].includes(targetTable);
    
    if (insertOneByOne) {
      console.log(`   ‚ö†Ô∏è  Insertando uno por uno para detectar problemas...`);
      for (let i = 0; i < sourceData.rows.length; i++) {
        const row = sourceData.rows[i];
        try {
          // Filtrar columnas: excluir las que son NULL y son JSON con default
          const columnsToInsert: string[] = [];
          const valuesToInsert: any[] = [];
          
          commonColumns.forEach(col => {
            let value = row[col];
            
            // Si es NULL y la columna es JSON, omitir la columna (usar√° el default)
            if (value === null || value === '' || value === 'null' || value === '""') {
              const colType = sourceColumnTypes.get(col);
              if (colType === 'json' || colType === 'jsonb') {
                // No incluir esta columna, dejar√° que use el default
                return;
              }
            }
            
            // Si es un array/object y la columna es JSON, convertir a string JSON
            const colType = sourceColumnTypes.get(col);
            if ((colType === 'json' || colType === 'jsonb') && (Array.isArray(value) || typeof value === 'object')) {
              value = JSON.stringify(value);
            }
            
            columnsToInsert.push(`"${col}"`);
            valuesToInsert.push(value);
          });
          
          if (columnsToInsert.length === 0) {
            console.log(`\n   ‚ö†Ô∏è  Registro ${i + 1} no tiene columnas v√°lidas, saltando...`);
            continue;
          }
          
          const placeholders = columnsToInsert.map((_, idx) => `$${idx + 1}`).join(', ');
          const columnsListLocal = columnsToInsert.join(', ');
          
          const insertQuery = `
            INSERT INTO "${targetTable}" (${columnsListLocal})
            VALUES (${placeholders})
            ON CONFLICT DO NOTHING
          `;
          
          await targetDb.query(insertQuery, valuesToInsert);
          totalInserted++;
          
          const progress = Math.round((totalInserted / sourceData.rows.length) * 100);
          process.stdout.write(`   üì§ Insertando... ${progress}% (${totalInserted}/${sourceData.rows.length})\r`);
        } catch (error: any) {
          console.error(`\n   ‚ùå Error en registro ${i + 1}:`, error.message);
          console.error(`   üìã Datos del registro:`, JSON.stringify(row, null, 2));
          throw error;
        }
      }
    } else {
      // Inserci√≥n normal en lotes
      for (let i = 0; i < sourceData.rows.length; i += batchSize) {
        const batch = sourceData.rows.slice(i, i + batchSize);
        
        const placeholders: string[] = [];
        const values: any[] = [];
        let valueIndex = 1;
        
        batch.forEach((row) => {
          const rowPlaceholders = commonColumns.map(() => `$${valueIndex++}`).join(', ');
          placeholders.push(`(${rowPlaceholders})`);
          commonColumns.forEach(col => {
            let value = row[col];
            
            // Sanitizar valores JSON/JSONB vac√≠os o inv√°lidos
            if (value === '' || value === 'null' || value === '""') {
              const colType = sourceColumnTypes.get(col);
              if (colType === 'json' || colType === 'jsonb') {
                value = null; // Convertir strings vac√≠os a NULL para columnas JSON
              }
            }
            
            values.push(value);
          });
        });
        
        const insertQuery = `
          INSERT INTO "${targetTable}" (${columnsList})
          VALUES ${placeholders.join(', ')}
          ON CONFLICT DO NOTHING
        `;
        
        await targetDb.query(insertQuery, values);
        totalInserted += batch.length;
        
        const progress = Math.round((totalInserted / sourceData.rows.length) * 100);
        process.stdout.write(`   üì§ Insertando... ${progress}% (${totalInserted}/${sourceData.rows.length})\r`);
      }
    }
    
    console.log(`\n   ‚úÖ Completado: ${totalInserted} registros copiados`);
    result.rowsCopied = totalInserted;
    result.duration = Date.now() - startTime;
    
  } catch (error: any) {
    console.error(`\n   ‚ùå Error: ${error.message}`);
    result.status = 'error';
    result.error = error.message;
    result.duration = Date.now() - startTime;
  }
  
  return result;
}

async function main() {
  const results: MigrationResult[] = [];
  
  try {
    console.log('üöÄ MIGRACI√ìN MEJORADA CON MAPEO DE COLUMNAS');
    console.log('=' .repeat(80));
    console.log('');
    console.log('üìç ORIGEN: 100.106.115.11 (PostgreSQL)');
    console.log('üìç DESTINO: Azure PostgreSQL');
    console.log('');
    console.log('üîß Caracter√≠sticas:');
    console.log('   ‚úÖ Mapeo autom√°tico de tablas (user ‚Üí usuarios, empresa ‚Üí clientes)');
    console.log('   ‚úÖ Exclusi√≥n de columnas incompatibles (old_id, modelo_id)');
    console.log('   ‚úÖ Orden correcto respetando foreign keys');
    console.log('');
    console.log('‚ö†Ô∏è  ADVERTENCIA: Esto eliminar√° los datos existentes en Azure!');
    console.log('');
    // Confirmaci√≥n autom√°tica para ejecuci√≥n desde npm
    // console.log('‚è∏Ô∏è  Presiona Ctrl+C para cancelar o Enter para continuar...');
    // await new Promise(resolve => {
    //   process.stdin.once('data', resolve);
    // });
    console.log('‚úÖ Iniciando migraci√≥n autom√°ticamente...');
    console.log('\nüîå Conectando...');
    await sourceDb.connect();
    console.log('‚úÖ Conectado a ORIGEN');
    
    await targetDb.connect();
    console.log('‚úÖ Conectado a DESTINO');
    
    console.log(`\nüì¶ Migrando ${tablesToMigrate.length} tablas...`);
    console.log('=' .repeat(80));
    
    for (let i = 0; i < tablesToMigrate.length; i++) {
      const tableConfig = tablesToMigrate[i];
      let sourceTable: string;
      let targetTable: string;
      
      if (typeof tableConfig === 'string') {
        sourceTable = tableConfig;
        targetTable = tableConfig;
      } else {
        sourceTable = tableConfig.source;
        targetTable = tableConfig.target;
      }
      
      console.log(`\n[${i + 1}/${tablesToMigrate.length}] ‚ñ∂Ô∏è  ${sourceTable} ‚Üí ${targetTable}`);
      
      const result = await migrateTable(sourceTable, targetTable);
      results.push(result);
      
      // Pausa breve entre tablas
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    // Resumen
    console.log('\n\n');
    console.log('=' .repeat(80));
    console.log('üìä RESUMEN FINAL');
    console.log('=' .repeat(80));
    console.log('');
    
    const successful = results.filter(r => r.status === 'success');
    const errors = results.filter(r => r.status === 'error');
    const skipped = results.filter(r => r.status === 'skipped');
    const totalRows = successful.reduce((sum, r) => sum + r.rowsCopied, 0);
    
    console.log(`‚úÖ Tablas migradas: ${successful.length}`);
    console.log(`‚ùå Errores: ${errors.length}`);
    console.log(`‚ö†Ô∏è  Saltadas: ${skipped.length}`);
    console.log(`üìä Total registros: ${totalRows.toLocaleString()}`);
    console.log('');
    
    if (errors.length > 0) {
      console.log('‚ùå ERRORES:');
      errors.forEach(r => {
        console.log(`   ‚Ä¢ ${r.table}: ${r.error}`);
      });
      console.log('');
    }
    
    if (successful.length > 0) {
      console.log('‚úÖ TABLAS MIGRADAS:');
      successful.forEach(r => {
        console.log(`   ‚Ä¢ ${r.table}: ${r.rowsCopied.toLocaleString()} registros`);
      });
      console.log('');
    }
    
    console.log('=' .repeat(80));
    console.log('üéâ Proceso completado!');
    console.log('');
    
  } catch (error: any) {
    console.error('\n‚ùå Error fatal:', error.message);
    process.exit(1);
  } finally {
    await sourceDb.end();
    await targetDb.end();
    console.log('üîå Conexiones cerradas\n');
  }
}

main().catch(console.error);
